{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Calculate anomalies after dedrifing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forcing_F13(tasdata, Ndata, model, years = None):\n",
    "    parameter_table = pd.read_csv('../data/best_estimated_parameters_allmembers4xCO2.csv', index_col=0)\n",
    "    if years == None:\n",
    "        GregoryT2x = parameter_table.loc[model,'GregoryT2x']\n",
    "        GregoryF2x = parameter_table.loc[model,'GregoryF2x']\n",
    "    if years == '1-20':\n",
    "        GregoryT2x = parameter_table.loc[model,'GregoryT2x_1-20']\n",
    "        GregoryF2x = parameter_table.loc[model,'GregoryF2x_1-20']\n",
    "    fbpar = GregoryF2x/GregoryT2x\n",
    "    F = Ndata + fbpar*tasdata\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tas_predictors(t, fixed_par, exptype = 'stepforcing', timevaryingforcing = []):\n",
    "    # compute components/predictors for T_n(t) = exp(-t/tau_n)*F(t) (* is a convolution)\n",
    "    # input for stepforcing: years, fixed parameters (timescales for stepforcing)\n",
    "    # stepforcing_ computes response to unit forcing,\n",
    "    # to be multiplied by the actual forcing afterwards\n",
    "    \n",
    "    # timevaryingforcing: need a forcing time series input\n",
    "    if exptype == 'stepforcing':\n",
    "        timescales = fixed_par; dim = len(timescales)\n",
    "        predictors = np.zeros((len(t),dim))\n",
    "        for i in range(0,dim): \n",
    "            predictors[:,i] = (1 - np.exp((-t)/timescales[i]))\n",
    "    elif exptype == 'timevaryingforcing': # need forcing input\n",
    "        # compute components T_n(t) = exp(-t/tau_n)*F(t) (Here * is a convolution)\n",
    "        timescales = fixed_par\n",
    "        lf = len(timevaryingforcing); dim = len(timescales)\n",
    "        predictors = np.full((lf,dim),np.nan)   \n",
    "\n",
    "        # compute exact predictors by integrating greens function\n",
    "        for k in range(0,dim):\n",
    "            # dot after 0 to create floating point numbers:\n",
    "            intgreensti = np.full((lf,lf),0.)   \n",
    "            for t in range(0,lf):\n",
    "                # compute one new contribution to the matrix:\n",
    "                intgreensti[t,0] = timescales[k]*(np.exp(-t/timescales[k]) - np.exp(-(t+1)/timescales[k]))\n",
    "                # take the rest from row above:\n",
    "                if t > 0:\n",
    "                    intgreensti[t,1:(t+1)] = intgreensti[t-1,0:t]\n",
    "            # compute discretized convolution integral by this matrix product:\n",
    "            predictors[:,k] = intgreensti@np.array(timevaryingforcing)\n",
    "    else:\n",
    "        print('unknown exptype')\n",
    "    return predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dpy(start_year, end_year, ds_calendar): # days per year\n",
    "    leap_boolean = [leap_year(year, calendar = ds_calendar)\\\n",
    "                    for year in range(start_year, end_year)]\n",
    "    leap_int = np.multiply(leap_boolean,1) # converts True/False to 1/0\n",
    "    \n",
    "    noleap_dpy = np.array(dpm[ds_calendar]).sum()\n",
    "    leap_dpy = noleap_dpy + leap_int  \n",
    "    return leap_dpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm = {'noleap': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       '365_day': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31], # I assume this is the same as noleap\n",
    "       'standard': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       'julian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31], ##### I think this should be correct\n",
    "       'proleptic_gregorian': [0, 31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],\n",
    "       '360_day': [0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30]\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function copied from: http://xarray.pydata.org/en/stable/examples/monthly-means.html\n",
    "def leap_year(year, calendar='standard'):\n",
    "    \"\"\"Determine if year is a leap year\"\"\"\n",
    "    leap = False\n",
    "    if ((calendar in ['standard', 'gregorian',\n",
    "        'proleptic_gregorian', 'julian']) and\n",
    "        (year % 4 == 0)):\n",
    "        leap = True\n",
    "        if ((calendar == 'proleptic_gregorian') and\n",
    "            (year % 100 == 0) and\n",
    "            (year % 400 != 0)):\n",
    "            leap = False\n",
    "        elif ((calendar in ['standard', 'gregorian']) and\n",
    "                 (year % 100 == 0) and (year % 400 != 0) and\n",
    "                 (year < 1583)):\n",
    "            leap = False\n",
    "    return leap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_time_in_parent = 60265\n",
    "parent_experiment_id = 'esm-hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnames_branchinfo_overview = ['exp', 'member', 'piControl branch time (days)', 'nearest time in table (days)', 'days difference', 'piControl branch time (year)']\n",
    "branchinfo_overview_df = pd.DataFrame(columns = columnames_branchinfo_overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'MPI-ESM1-2-LR'\n",
    "experiments = [\n",
    "    'esm-ssp119',\n",
    "    'esm-ssp126',\n",
    "    'esm-ssp245',\n",
    "    'esm-ssp370',\n",
    "    'esm-ssp534-over',\n",
    "]\n",
    "var_list = ['tas', 'rlut', 'rsut', 'rsdt']\n",
    "historical_path = f'../data/processed_data/{model}/esm-hist/climate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will only do 10 ensemble members even if 30 are available, because I can't tell where the branch point is for members 11-30\n",
    "available_members = [f'r{run}i1p1f1' for run in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "piControl_path = f'../data/processed_data/{model}/esm-piControl/climate/'\n",
    "branch_time_file = f'../data/branch_times/{model}_branch_times.csv'\n",
    "table = pd.read_table(branch_time_file,index_col=0, sep = ',')\n",
    "for exp in experiments:\n",
    "    exptable = table.loc[table['exp'] == exp]\n",
    "    exp_path=f'../output/processed/{model}/{exp}/climate/'\n",
    "    for member in available_members:\n",
    "        os.makedirs(os.path.join('..', 'output', 'processed', model, exp, 'anomalies'), exist_ok=True)\n",
    "        member_df = exptable.loc[exptable['member'] == member]\n",
    "        member_calendar = 'proleptic_gregorian'\n",
    "\n",
    "        # load exp data\n",
    "        exp_filename = member + '.csv'\n",
    "        exp_data = pd.read_table(exp_path + exp_filename, index_col=0, sep = ',')\n",
    "        if np.isnan(exp_data).values.any():\n",
    "            print('Warning: data contain NaN')\n",
    "        exp_years = exp_data.index.values\n",
    "        if len(str(exp_years[0]))>4:\n",
    "            # then it contains info about start month too,\n",
    "            # because experiment does not start in january\n",
    "            exp_years = [str(yr)[:4] for yr in exp_years] # this code is not tested yet\n",
    "        exp_start_year = exp_years[0]\n",
    "        exp_len = len(exp_years)\n",
    "\n",
    "        # find historical parent member \n",
    "        parent_member = member_df['parent_variant_id'].values[0]\n",
    "        parent_table = table.loc[table['exp'] == 'esm-hist']\n",
    "        parent_df = parent_table.loc[parent_table['member'] == parent_member]\n",
    "        piControl_timeunit_start_year = int(parent_df['parent_time_units'].values[0][11:15])\n",
    "\n",
    "        # find first year of historical parent (usually 1850)\n",
    "        historical_parent_filename = model + '_esm-hist_' + parent_member + '_means.csv'\n",
    "        historical_parent_data = pd.read_table(historical_path + historical_parent_filename, index_col=0, sep = ',')\n",
    "        first_year_historical_parent = historical_parent_data.index.values[0]\n",
    "\n",
    "        # check branch for historical parent only\n",
    "        branch_time_days = int(float(parent_df['branch_time_in_parent'].values[0]))\n",
    "        #branch_time_days = int(''.join(filter(str.isdigit, parent_df['branch_time_in_parent'].values[0])))\n",
    "\n",
    "        #branch_time_days = parent_df['branch_time_in_parent'].values[0]\n",
    "        piControl_member = parent_df['parent_variant_id'].values[0]\n",
    "\n",
    "        # load piControl values. \n",
    "        piControl_filename = model + '_esm-piControl_' + piControl_member + '_means.csv'\n",
    "        piControl_data = pd.read_table(piControl_path + piControl_filename, index_col=0, sep = ',')\n",
    "        if np.isnan(piControl_data).values.any():\n",
    "            print('Warning: piControl data contain NaN')\n",
    "        piControl_years = piControl_data.index.values\n",
    "        piControl_start_year = piControl_years[0]\n",
    "\n",
    "        piControl_start_diff = piControl_start_year - piControl_timeunit_start_year\n",
    "        if piControl_start_year != piControl_timeunit_start_year:\n",
    "            print('Note: piControl starts', piControl_start_diff, 'years after its time unit starts')\n",
    "            #piControl_timeunit_start_year = piControl_timeunit_correction(model, exp, member, piControl_timeunit_start_year, piControl_start_year)\n",
    "\n",
    "        if model in ['CanESM5', 'CanESM5-CanOE']:\n",
    "            len_days_table = 6000 # since piControl starts a long time after its time unit starts\n",
    "        else:\n",
    "            len_days_table = 1500\n",
    "        days_table = np.append([0],np.cumsum(dpy(piControl_timeunit_start_year,piControl_timeunit_start_year+len_days_table, member_calendar)))    \n",
    "        # find index of element closest to branch_time_days:\n",
    "        years_since_piControl_timeunit_start = (np.abs(days_table - branch_time_days)).argmin()\n",
    "        years_since_piControl_start = years_since_piControl_timeunit_start - piControl_start_diff\n",
    "\n",
    "        # years_since_piControl_start = branch_time_correction(\n",
    "        #     model, exp, member, branch_time_days, piControl_timeunit_start_year, piControl_start_year, years_since_piControl_start\n",
    "        # )\n",
    "        # write function to correct this for some models\n",
    "        # applies for NorESM\n",
    "\n",
    "        piControl_branch_year = piControl_start_year + years_since_piControl_start\n",
    "\n",
    "        # collect info in overview table:\n",
    "        exp_branchinfo_df = pd.DataFrame([[exp, member, branch_time_days, days_table[years_since_piControl_timeunit_start], days_table[years_since_piControl_timeunit_start] - branch_time_days, piControl_branch_year]], columns = columnames_branchinfo_overview)\n",
    "        branchinfo_overview_df = pd.concat([branchinfo_overview_df, exp_branchinfo_df], ignore_index = True)\n",
    "\n",
    "        years_since_piControl_branch = exp_years - first_year_historical_parent\n",
    "        corr_piControl_years = piControl_branch_year + years_since_piControl_branch #np.arange(165,251)\n",
    "\n",
    "        # Anomalies and piControl_linfit should have the same size and time index as exp_data\n",
    "        # therefore we just copy, and then overwrite the values\n",
    "        anomalies = exp_data.copy(deep=True)\n",
    "        piControl_linfit = exp_data.copy(deep=True)\n",
    "        for var in var_list:\n",
    "            p1 = np.polyfit(piControl_years, piControl_data[var], 1)\n",
    "\n",
    "            # make linear fit\n",
    "            if set(corr_piControl_years).issubset(set(piControl_years)):\n",
    "                # then all corr_piControl_years are available\n",
    "                piControl_linfit[var] = np.polyval(p1,corr_piControl_years)\n",
    "            else:\n",
    "                # extend the linear fit outside the range of the original piControl years\n",
    "                # used just for plotting before?\n",
    "                #corr_piControl_years = list(set(corr_piControl_years).union(set(piControl_years)))\n",
    "                #corr_piControl_years.sort()\n",
    "                piControl_linfit[var] = np.polyval(p1,corr_piControl_years)\n",
    "\n",
    "            anomalies[var] = exp_data[var] - piControl_linfit[var]\n",
    "        anomalies.to_csv(os.path.join('..', 'output', 'processed', model, exp, 'anomalies', f'{member}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-cmip6-nonco2-forcing Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-cmip6-nonco2-forcing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
